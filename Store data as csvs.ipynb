{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readout data from database\n",
    "\n",
    "**Note!** This notebook cannot be run due to its dependence on the underlying Datajoint database. It is only meant to showcase how the data was extracted from the data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting slaturnus@172.25.240.205:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/slaturnus/.local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/gpfs01/berens/user/slaturnus/.local/lib/python3.5/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# DATAJOINT\n",
    "import datajoint as dj\n",
    "dj.config.load('./utils/dj_mysql_conf.json')\n",
    "c = dj.conn()\n",
    "\n",
    "from schemata.cell import *\n",
    "from schemata.density import *\n",
    "from schemata.morphometry import *\n",
    "from schemata.features import *\n",
    "from schemata.classification import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../publications/morphology-benchmark/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "\n",
    "key = dict(reduction_id=0)\n",
    "for s in (FeatureMap()& key & \"part_id=1\" & \"statistic_id < 110\").fetch('statistic_id'):\n",
    "    for p in [(1,'full'),(2,'axon'),(3,'dendrite')]:\n",
    "        key['statistic_id'] = s\n",
    "        key['part_id'] = p[0]\n",
    "        df = FeatureMap().get_as_dataframe(key, \"type != 'pyr' and part_id <4 and ds_id<6 and ds_id != 2\")\n",
    "        df.T.to_csv(path +\"data/features/statistic_id_%i_%s.csv\"%(s,p[1]), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairwise classification performance\n",
    "df = pd.DataFrame((PairwiseClassificationImbalanced().CVRun() & \"statistic_id < 110\" & \"ds_id !=2 and ds_id < 6\").fetch(as_dict=True))\n",
    "del df['training_indices']\n",
    "del df['test_indices']\n",
    "del df['reduction_id']\n",
    "df.to_csv(path + \"data/classification/pairwise_classification_performances.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi class performance\n",
    "df_multi = pd.DataFrame((MultiClassClassificationImbalanced.CVRun() & \"statistic_id < 110\" & \"ds_id !=2 and ds_id < 6\").fetch(as_dict=True))\n",
    "\n",
    "del df_multi['training_indices']\n",
    "del df_multi['test_indices']\n",
    "del df_multi['reduction_id']\n",
    "\n",
    "df_multi.to_csv(path + \"data/classification/multiclass_classification_performances.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "df_dm = pd.DataFrame(Statistic().DensityMap().fetch(as_dict=True))\n",
    "df_graph = pd.DataFrame(Statistic().Graph().fetch(as_dict=True))\n",
    "df_morphometrics = pd.DataFrame(Statistic().Morphometry().fetch(as_dict=True))\n",
    "df_morph_dist = pd.DataFrame(Statistic().MorphometryDistribution().fetch(as_dict=True))\n",
    "df_combined = pd.DataFrame(Statistic().Combined().fetch(as_dict=True))\n",
    "df_persistence = pd.DataFrame(Statistic().Persistence().fetch(as_dict=True))\n",
    "\n",
    "df_statistics = pd.DataFrame()\n",
    "\n",
    "for d in [df_dm, df_graph,df_morphometrics, df_morph_dist, df_persistence, df_combined]:\n",
    "    df_statistics = pd.concat((df_statistics, d[['statistic_id', 'statistic_name']]))\n",
    "\n",
    "df_statistics.to_csv(path + \"data/statistic_descriptions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the used reconstructions\n",
    "ds_ids = [1,3,4,5]\n",
    "selected_cells = []\n",
    "for ds_id in ds_ids:\n",
    "    cell_types = np.unique(((Cell() & \"ds_id = %s\"%str(ds_id)) - Cell().Ignore()).fetch('type'))\n",
    "\n",
    "    for c_t in cell_types:\n",
    "        if c_t not in ['pyr', 'IPC', 'UTPC', 'TPC', 'CBC8', 'CBC9']:\n",
    "            selected_cells.append(list(((Cell() - Cell().Ignore())& \"ds_id = %s\"%str(ds_id) & \"type='%s'\"%c_t).fetch()[0]))\n",
    "        \n",
    "\n",
    "cells = pd.DataFrame(selected_cells, columns=['ds_id', 'c_num', 'type'])\n",
    "\n",
    "# rename the cell type to be consistent with L4 paper\n",
    "cells.loc[(cells['ds_id'] == 5) & (cells['type'] == 'BC'),'type'] = 'LBC'\n",
    "cells.loc[(cells['ds_id'] == 5) & (cells['type'] == 'SC'),'type'] = 'SBC'\n",
    "cells.loc[(cells['ds_id'] == 5) & (cells['type'] == 'HEC'),'type'] = 'HBC'\n",
    "cells.to_csv(path + \"/data/reconstructions/selected_cells.csv\")\n",
    "\n",
    "# get the number of cells\n",
    "\n",
    "cell_numbers = pd.DataFrame((Cell() - Cell().Ignore()).fetch(as_dict=True))\n",
    "cell_numbers = cell_numbers.groupby(['ds_id', 'type']).count().reset_index()\n",
    "\n",
    "cell_numbers.loc[(cell_numbers['ds_id'] == 5) & (cell_numbers['type'] == 'BC'),'type'] = 'LBC'\n",
    "cell_numbers.loc[(cell_numbers['ds_id'] == 5) & (cell_numbers['type'] == 'SC'),'type'] = 'SBC'\n",
    "cell_numbers.loc[(cell_numbers['ds_id'] == 5) & (cell_numbers['type'] == 'HEC'),'type'] = 'HBC'\n",
    "\n",
    " cell_numbers[(cell_numbers['ds_id'] < 6) & (cell_numbers['ds_id'] != 2) & (cell_numbers['type'] != 'pyr')].to_csv(\"./data/reconstructions/cell_numbers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, item in cells[(cells['ds_id'] < 6) & (cells['ds_id'] != 2)].iterrows():\n",
    "    neuron = Neuron().get_tree({'c_num': item['c_num'], 'ds_id': item['ds_id'], 'reduction_id':0})\n",
    "    neuron.write_to_swc(\"ds_%i_cell_%i\"%(item['ds_id'], item['c_num']), path=path + 'data/reconstructions/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
