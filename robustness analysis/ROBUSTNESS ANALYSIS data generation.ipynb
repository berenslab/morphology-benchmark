{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness analysis data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!** This notebook cannot be run like this because it pulls its data from the internal Datajoint database. It is meant to showcase the truncation procedure and feature computation of each neuron. \n",
    "If you want to reproduce the analysis please adjust the data read in accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting slaturnus@172.25.240.205:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# DATAJOINT\n",
    "import datajoint as dj\n",
    "dj.config.load('./utils/dj_mysql_conf.json')\n",
    "c = dj.conn()\n",
    "\n",
    "from schemata.cell import *\n",
    "from schemata.classification import *\n",
    "schema = dj.schema('agberens_morphologies', locals())\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from utils import NeuronTree as nt\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "# PLOTTING\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BC', 'BPC', 'BTC', 'ChC', 'DBC', 'MC', 'NGC', 'pyr'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique((Cell() & 'ds_id =3').fetch('type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data for each type individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = pd.DataFrame((Neuron()*Cell() & dict(ds_id=3, reduction_id=0)& \"type!='pyr'\").fetch(as_dict=True))\n",
    "types.to_csv('./data/types.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_keys = (Neuron()*Cell() & dict(ds_id=3, reduction_id=0)& dj.OrList([\"type='%s'\"%k for k in np.unique(types['type'])])).proj().fetch(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "\n",
    "for k in neuron_keys:\n",
    "    trees.append(Neuron().get_tree(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components(G_):\n",
    "    seen = set()\n",
    "    for v in G_:\n",
    "        if v not in seen:\n",
    "            c = set(nx.bfs_tree(G_,v))\n",
    "            yield c\n",
    "            seen.update(c)\n",
    "\n",
    "def truncate_branches(G, perc=.1, no_trunc_branches=None):\n",
    "\n",
    "    branchpoints = G.get_branchpoints()\n",
    "    branchorders = G.get_branch_order()\n",
    "\n",
    "    # identify points that are farthest away in terms of branch order\n",
    "    bp_bo = np.array([branchorders[point] for point in branchpoints])\n",
    "    no_branchpoints = len(bp_bo)\n",
    "\n",
    "    if perc is not None:\n",
    "        no_to_cut = int(np.round(no_branchpoints * perc))     \n",
    "    else:\n",
    "        no_to_cut = int(round(no_trunc_branches/2))     # since one branch point removes two branches\n",
    "\n",
    "    sorted_idx = np.argsort(bp_bo)\n",
    "\n",
    "    G_ = copy.deepcopy(G.get_graph())\n",
    "    \n",
    "    selected_bp = branchpoints[sorted_idx[-no_to_cut:]]\n",
    "    children_ids = []\n",
    "\n",
    "    for k in range(len(selected_bp)):\n",
    "        children_ids +=list(G_[selected_bp[k]].keys())\n",
    "        \n",
    "    if no_to_cut*2 >= len(children_ids):\n",
    "        choice = children_ids\n",
    "    else:\n",
    "        choice = np.random.choice(children_ids,int(np.round(len(branchpoints) *2 * perc)),replace=False )\n",
    "    \n",
    "    to_delete = []\n",
    "    for d in choice:\n",
    "        to_delete += nx.bfs_tree(G_,d).nodes()\n",
    "        \n",
    "    G_.remove_nodes_from(to_delete)\n",
    "    return nt.NeuronTree(graph=G_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def projection(G, u, v):\n",
    "    n = G.node[u]['pos']\n",
    "    r = G.node[v]['pos']\n",
    "    return np.dot((n - r), np.array([0,0,1]))\n",
    "\n",
    "def calculate_truncated_features(perc, trees, neuron_keys, method='branch points', folder='full'):\n",
    "    \n",
    "\n",
    "    try:\n",
    "        morphometry_data = pd.read_csv('./data/'+folder+'/morphometry_truncated_%0.2f.csv'%(perc))\n",
    "    except FileNotFoundError:\n",
    "        morphometry_data = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        persistence_data = pd.read_csv('./data/'+folder+'/persistence_truncated_%0.2f.csv'%(perc))\n",
    "    except FileNotFoundError:\n",
    "        persistence_data = pd.DataFrame()\n",
    "        \n",
    "    try:\n",
    "        point_cloud_data = pd.read_csv('./data/'+folder+'/point_cloud_truncated_%0.2f.csv'%(perc))\n",
    "    except FileNotFoundError:\n",
    "        point_cloud_data = pd.DataFrame()\n",
    "    \n",
    "    for k,t in enumerate(trees):\n",
    "        if method == 'nodes':\n",
    "            T = t.truncate_nodes(perc=perc)\n",
    "        elif method == 'branch points':\n",
    "            T = truncate_branches(t,perc=perc)\n",
    "                \n",
    "        if morphometry_data.empty or (neuron_keys[k]['c_num'] not in morphometry_data['c_num'].values) :\n",
    "\n",
    "            # create morphometric statistics vector\n",
    "            z = copy.copy(neuron_keys[k])\n",
    "            z['truncated'] = perc\n",
    "\n",
    "            z['branch_points'] = T.get_branchpoints().size\n",
    "            extend = T.get_extend()\n",
    "\n",
    "            z['width'] = extend[0]\n",
    "            z['depth'] = extend[1]\n",
    "            z['height'] = extend[2]\n",
    "\n",
    "            tips = T.get_tips()\n",
    "\n",
    "            z['tips'] = tips.size\n",
    "\n",
    "            z['stems'] = len(T.edges(1))\n",
    "\n",
    "            z['total_length'] = np.sum(list(nx.get_edge_attributes(T.get_graph(), 'path_length').values()))\n",
    "            # get all radii\n",
    "            radii = nx.get_node_attributes(T.get_graph(), 'radius')\n",
    "            # delete the soma\n",
    "            radii.pop(T.get_root())\n",
    "            z['avg_thickness'] = np.mean(list(radii.values()))\n",
    "           \n",
    "            z['total_surface'] = np.sum(list(T.get_surface().values()))\n",
    "            z['total_volume'] = np.sum(list(T.get_volume().values()))\n",
    "\n",
    "            z['max_path_dist_to_soma'] = np.max(T.get_distance_dist()[1])\n",
    "            z['max_branch_order'] = np.max(list(T.get_branch_order().values()))\n",
    "\n",
    "            path_angles = []\n",
    "            for p1 in T.get_path_angles().items():\n",
    "                if p1[1].values():\n",
    "                    path_angles += list(list(p1[1].values())[0].values())\n",
    "\n",
    "            z['max_path_angle'] = np.percentile(path_angles,99.5)\n",
    "            z['median_path_angle'] = np.median(path_angles)\n",
    "\n",
    "            R = T.get_mst()\n",
    "            segment_length = R.get_segment_length()\n",
    "            terminal_segment_pl = [item[1] for item in segment_length.items() if item[0][1] in tips]\n",
    "            intermediate_segment_pl = [item[1] for item in segment_length.items() if item[0][1] not in tips]\n",
    "\n",
    "            z['max_segment_path_length'] = np.max(list(segment_length.values()))\n",
    "            z['median_intermediate_segment_pl'] = np.median([0] + intermediate_segment_pl)\n",
    "            z['median_terminal_segment_pl'] = np.median(terminal_segment_pl)\n",
    "\n",
    "            tortuosity = [e[2]['path_length'] / e[2]['euclidean_dist'] for e in R.edges(data=True)]\n",
    "\n",
    "            z['max_tortuosity'] = np.log(np.percentile(tortuosity,99.5))\n",
    "            z['median_tortuosity'] = np.log(np.median(tortuosity))\n",
    "\n",
    "            branch_angles = R.get_branch_angles()\n",
    "            z['max_branch_angle'] = np.max(branch_angles)\n",
    "            z['min_branch_angle'] = np.min(branch_angles)\n",
    "            z['mean_branch_angle'] = np.mean(branch_angles)\n",
    "\n",
    "            # get maximal degree within data\n",
    "            z['max_degree'] = np.max([item[1] for item in R.get_graph().out_degree().items() if item[0] != R.get_root()])\n",
    "\n",
    "            # get tree asymmetry\n",
    "            weights, psad = R.get_psad()\n",
    "            if np.sum(list(weights.values())) != 0:\n",
    "                z['tree_asymmetry'] = np.sum([weights[k]*psad[k] for k in psad.keys()])/np.sum(list(weights.values()))\n",
    "            else:\n",
    "                z['tree_asymmetry'] = 0\n",
    "\n",
    "\n",
    "            morphometry_data = morphometry_data.append(pd.DataFrame(z, index=['c_num']))\n",
    "        \n",
    "        #### get persistence\n",
    "        if persistence_data.empty or (neuron_keys[k]['c_num'] not in persistence_data['c_num'].values) :\n",
    "            try:\n",
    "                persistence = T.get_persistence(f=projection)\n",
    "                persistence['c_num'] = z['c_num']\n",
    "\n",
    "                persistence_data = persistence_data.append(persistence)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "        ### sample point cloud\n",
    "        if point_cloud_data.empty or (neuron_keys[k]['c_num'] not in point_cloud_data['c_num'].values) :\n",
    "            pc = nt.NeuronTree.resample_nodes(T.get_graph(), 0.025) \n",
    "            point_cloud = pd.DataFrame(pc, columns=['x','y','z'])\n",
    "            point_cloud['ds_id'] = neuron_keys[k]['ds_id']\n",
    "            point_cloud['c_num'] = neuron_keys[k]['c_num']\n",
    "            point_cloud_data = point_cloud_data.append(point_cloud)\n",
    "        \n",
    "                                   \n",
    "    morphometry_data.to_csv('./data/'+folder+'/morphometry_truncated_%0.2f.csv'%(perc))\n",
    "    persistence_data.to_csv('./data/'+folder+'/persistence_truncated_%0.2f.csv'%(perc))\n",
    "    point_cloud_data.to_csv('./data/'+folder+'/point_cloud_truncated_%0.2f.csv'%(perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole trees\n",
    "method = 'branch points'\n",
    "truncation = np.array(range(0,10))/10\n",
    "data = trees\n",
    "folder = 'full' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(8) as pool:\n",
    "    most_trunc = pool.map(partial(calculate_truncated_features,trees=data, neuron_keys=neuron_keys, method=method, folder=folder), truncation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
